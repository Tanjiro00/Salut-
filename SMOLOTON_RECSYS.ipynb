{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "FDu0ZeE6EE1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import spacy\n",
        "\n",
        "\n",
        "class Place:\n",
        "  def __init__(self,  tags, vec_model, text_tokenizer):\n",
        "    '''\n",
        "    tags = tags for each place or text prompt\n",
        "    vec_model = Language Model for getting tags embeddings\n",
        "    '''\n",
        "    self.vec_model = vec_model\n",
        "    self.text_tokenizer = text_tokenizer\n",
        "    self.tags = tags\n",
        "    self.embs = torch.tensor([])\n",
        "\n",
        "\n",
        "  def compute_embeddings(self, is_return=False):\n",
        "    tensor_tags = self.text_tokenizer(self.tags, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "      model_out = self.vec_model(**tensor_tags)\n",
        "    self.embs = self._mean_pooling(model_out, tensor_tags['attention_mask']).squeeze()\n",
        "    if is_return:\n",
        "      return self.embs\n",
        "\n",
        "\n",
        "\n",
        "  def _mean_pooling(self, model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask"
      ],
      "metadata": {
        "id": "Swn4BbhXE5Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class User:\n",
        "  def __init__(self,  tags, prompt, vec_model, text_tokenizer, liked_history=None):\n",
        "    self.vec_model = vec_model\n",
        "    self.text_tokenizer = text_tokenizer\n",
        "    self.prompt = prompt\n",
        "    self.tags = tags\n",
        "    self.cos = torch.nn.CosineSimilarity(dim=-1)\n",
        "    self.liked_history = liked_history\n",
        "    tensor_tags = self.text_tokenizer(tags, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
        "    tensor_prompt = self.text_tokenizer(prompt, padding=True, truncation=True, max_length=50, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "      model_out_tags = self.vec_model(**tensor_tags)\n",
        "      model_out_prompt = self.vec_model(**tensor_prompt)\n",
        "    embs_tags = self._mean_pooling(model_out_tags, tensor_tags['attention_mask']).squeeze()\n",
        "    embs_prompt = self._mean_pooling(model_out_prompt, tensor_prompt['attention_mask']).squeeze()\n",
        "    self.user_embs = (embs_tags + embs_prompt) / 2\n",
        "\n",
        "\n",
        "  def get_topk_rec(self, idx, place_embeddings, k=5):\n",
        "    '''\n",
        "    func get index of person and return cos_sim of person with every man from BD\n",
        "    '''\n",
        "    man = self.user_embs[idx]\n",
        "    indices = torch.tensor([i for i in range(place_embeddings.shape[0])])\n",
        "    # other_embeddings = torch.index_select(self.user_embs, 0, indices)\n",
        "    cosine_arr = self.cos(man, place_embeddings)\n",
        "    try:\n",
        "      max_sim_idx = torch.topk(cosine_arr, k).indices\n",
        "    except:\n",
        "      max_sim_idx = torch.topk(cosine_arr, place_embeddings.shape[0]).indices\n",
        "    max_sim_places = indices[max_sim_idx]\n",
        "    return max_sim_places\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def _mean_pooling(self, model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask"
      ],
      "metadata": {
        "id": "mLcSv0br32_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")\n",
        "sbert_model = AutoModel.from_pretrained(\"ai-forever/sbert_large_nlu_ru\")"
      ],
      "metadata": {
        "id": "Ms678lxjyVUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm_places = Place([ \"Спортивный зал\", \"Музей поэтов\", \"Театр искусств\"], sbert_model, tokenizer)\n",
        "sm_man = User(tags=[\"поэты\", \"Пушкин\"], prompt=[\"Мне очень нравится творчество Пушкина\"], vec_model=sbert_model, text_tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "Y3qlQuoVyVdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "place_embs = sm_places.compute_embeddings(True)\n",
        "sm_man.get_topk_rec(0, place_embs, k=5)"
      ],
      "metadata": {
        "id": "wG2-eJfdObN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "place_embs.shape"
      ],
      "metadata": {
        "id": "x-0aEhCbtTEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X141PBlquVuY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}